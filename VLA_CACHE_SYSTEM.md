# VLA Cache System - ì™„ì „ ê³ ì • ìºì‹±

## ğŸ¯ ë¬¸ì œ í•´ê²°

### ì´ì „ ë¬¸ì œ
```
ğŸ“¦ Loaded episode_20251030_025209 (new format)
   Samples: 169, Sensor: True, VL Cache: 0/57
```

**ì›ì¸**: ìºì‹œ ê²½ë¡œê°€ ë‹¤ìŒ ì •ë³´ë¡œ ìƒì„±ë˜ì—ˆê¸° ë•Œë¬¸ì— ë¶ˆì•ˆì •í–ˆìŠµë‹ˆë‹¤:
- Hash of: `{trajectory_key} + "||" + {instruction} + "||" + {image_paths}`
- instructionì´ë‚˜ image_pathsê°€ ì¡°ê¸ˆë§Œ ë°”ë€Œì–´ë„ ìºì‹œë¥¼ ëª» ì°¾ìŒ

### ìƒˆë¡œìš´ ì†”ë£¨ì…˜: ì™„ì „ ê³ ì • ìºì‹±

**ìºì‹œ ê²½ë¡œ**: `{dataset_name}_vlm{vlm_idx}.pt` ë§Œ ì‚¬ìš©

```python
# ì˜ˆì‹œ:
# recv_all_20251027_170308_vlm0.pt
# episode_20251030_025119_vlm150.pt
```

**ì¥ì **:
- âœ… Instruction ë³€ê²½ì—ë„ ìºì‹œ ìœ ì§€
- âœ… Image path ë³€ê²½ì—ë„ ìºì‹œ ìœ ì§€
- âœ… ë°ì´í„°ì…‹ ì´ë¦„ + VLM indexë§Œìœ¼ë¡œ ì™„ì „ ê²°ì •
- âœ… ì•ˆì •ì ì´ê³  ì˜ˆì¸¡ ê°€ëŠ¥í•œ ìºì‹±

---

## ğŸ“ ìˆ˜ì •ëœ íŒŒì¼ë“¤

### 1. vla_cache_manager.py (ì‹ ê·œ ìƒì„±)

**VLACacheManager í´ë˜ìŠ¤**:
```python
class VLACacheManager:
    def get_cache_path(self, dataset_name: str, vlm_idx: int) -> Path:
        """ì™„ì „ ê³ ì • ìºì‹œ ê²½ë¡œ"""
        return self.cache_dir / f"{dataset_name}_vlm{vlm_idx}.pt"

    def cache_exists(self, dataset_name: str, vlm_idx: int) -> bool:
        """ìºì‹œ ì¡´ì¬ í™•ì¸"""

    def load_cache(self, dataset_name: str, vlm_idx: int, device="cpu"):
        """ìºì‹œ ë¡œë“œ"""

    def save_cache(self, dataset_name: str, vlm_idx: int, vl_features):
        """ìºì‹œ ì €ì¥ (atomic + cache limit ìë™ ì ìš©)"""
```

**íŠ¹ì§•**:
- Atomic save with file locking (ë™ì‹œ ì ‘ê·¼ ì•ˆì „)
- ìë™ ìºì‹œ ìš©ëŸ‰ ì œí•œ (ê¸°ë³¸ 50GB)
- í†µê³„ ë° ê´€ë¦¬ ê¸°ëŠ¥ ì œê³µ

---

### 2. vla_datasets/unified_dataset.py (ìˆ˜ì •)

#### Line 293-321: `_scan_vl_cache()` ë©”ì„œë“œ
```python
def _scan_vl_cache(self):
    """Pre-scan VL cache files using VLACacheManager"""
    from vla_cache_manager import get_cache_manager

    cache_mgr = get_cache_manager(cache_dir=str(self.cache_root))
    self.vl_cache_files = {}
    dataset_name = self.data_dir.name

    if self.format == 'old':
        for action_step in range(self.max_action_steps):
            vlm_idx = min(action_step * self.action_step_size, len(self.actions) - 1)
            if vlm_idx not in self.vl_cache_files:
                if cache_mgr.cache_exists(dataset_name, vlm_idx):
                    self.vl_cache_files[vlm_idx] = cache_mgr.get_cache_path(dataset_name, vlm_idx)
                else:
                    self.vl_cache_files[vlm_idx] = None

    else:  # new format
        num_vlm_steps = (self._total_samples + self.vlm_reuse_count - 1) // self.vlm_reuse_count
        for i in range(num_vlm_steps):
            vlm_idx = i * self.vlm_interval
            if cache_mgr.cache_exists(dataset_name, vlm_idx):
                self.vl_cache_files[vlm_idx] = cache_mgr.get_cache_path(dataset_name, vlm_idx)
            else:
                self.vl_cache_files[vlm_idx] = None

    self.cache_found_count = sum(1 for p in self.vl_cache_files.values() if p is not None)
```

#### Line 412-444: `_load_vl_or_images()` ë©”ì„œë“œ
```python
def _load_vl_or_images(self, vlm_idx):
    """Load VL cache or return image paths using VLACacheManager"""
    from vla_cache_manager import get_cache_manager

    vl_cache = None
    image_paths = []

    cache_path = self.vl_cache_files.get(vlm_idx)

    if cache_path:
        # Use cache manager for loading
        cache_mgr = get_cache_manager(cache_dir=str(self.cache_root))
        vl_cache = cache_mgr.load_cache(
            dataset_name=self.data_dir.name,
            vlm_idx=vlm_idx,
            device="cpu"
        )
        if vl_cache is not None:
            return vl_cache, None

    # Fallback to image paths
    ...
```

**ë³€ê²½ ì‚¬í•­**:
- Hash ê¸°ë°˜ ê²½ë¡œ â†’ VLACacheManager ì‚¬ìš©
- `cache_mgr.cache_exists()` ë° `cache_mgr.load_cache()` ì‚¬ìš©
- ì™„ì „íˆ ê²°ì •ë¡ ì ì¸ ìºì‹œ íƒìƒ‰

---

### 3. Make_VL_cache.py (ëŒ€í­ ìˆ˜ì •)

#### Import ì¶”ê°€
```python
from vla_cache_manager import get_cache_manager
```

#### Line 37-64: VLACacheManager ì´ˆê¸°í™”
```python
# VLACacheManager ì´ˆê¸°í™”
cache_mgr = get_cache_manager(
    cache_dir=str(base_cache_dir),
    cache_limit_gb=50.0
)
```

#### Line 108-136: ìºì‹œ ì²´í¬ ë¡œì§
```python
# --- ë¯¸ìŠ¤/ìŠ¤í‚µ ë¶„ë¦¬ (VLACacheManager ì‚¬ìš©) ---
miss_items = []
for cache_key, vlm_idx, txt, views in zip(cache_keys, vlm_indices, texts, image_paths_list):
    # cache_key format: "{dataset_name}_vlm{vlm_idx}"
    # Extract dataset_name
    dataset_name = cache_key.rsplit("_vlm", 1)[0]

    if not cache_mgr.cache_exists(dataset_name, vlm_idx):
        miss_items.append({
            "text": txt,
            "views": views,
            "dataset_name": dataset_name,
            "vlm_idx": vlm_idx
        })
    else:
        total_skipped += 1
```

#### Line 179-187: ìºì‹œ ì €ì¥ ë¡œì§
```python
for j, item in enumerate(sub_items):
    pooled_single = pooled_batch[j:j+1]
    # VLACacheManagerë¡œ ì €ì¥
    cache_mgr.save_cache(
        dataset_name=item["dataset_name"],
        vlm_idx=item["vlm_idx"],
        vl_features=pooled_single
    )
    total_cached += 1
```

**ë³€ê²½ ì‚¬í•­**:
- `key_mode`, `rank_sharded_cache` íŒŒë¼ë¯¸í„° ì œê±° (ë” ì´ìƒ í•„ìš” ì—†ìŒ)
- Hash ê¸°ë°˜ `_cache_path_for()` í•¨ìˆ˜ ì œê±°
- `_local_atomic_save()`, `_local_enforce_cache_limit()` ì œê±° (VLACacheManagerê°€ ì²˜ë¦¬)
- ì™„ì „íˆ VLACacheManager ê¸°ë°˜ìœ¼ë¡œ ì „í™˜

---

## ğŸ” ìºì‹œ í‚¤ ìƒì„± ë°©ì‹

### Datasetì—ì„œ ìƒì„± (unified_dataset.py)

#### Old Format (Line 367):
```python
cache_key = f"{self.data_dir.name}_vlm{vlm_idx}"
# ì˜ˆ: recv_all_20251027_170308_vlm0
```

#### New Format (Line 397):
```python
cache_key = f"{self.data_dir.name}_vlm{vlm_idx}"
# ì˜ˆ: episode_20251030_025119_vlm150
```

**ì¤‘ìš”**:
- `self.data_dir.name`ì€ ë°ì´í„°ì…‹ í´ë” ì´ë¦„ (ì˜ˆ: `recv_all_20251027_170308`, `episode_20251030_025119`)
- `vlm_idx`ëŠ” VLMì´ ì‹¤í–‰ë˜ëŠ” ì¸ë±ìŠ¤ (0, 3, 6, ... ë˜ëŠ” 0, 10, 20, ...)

---

## ğŸ§ª í…ŒìŠ¤íŠ¸ ë°©ë²•

### VLACacheManager ë‹¨ë… í…ŒìŠ¤íŠ¸
```bash
python vla_cache_manager.py
```

**ì¶œë ¥ ì˜ˆì‹œ**:
```
ğŸ§ª Testing VLA Cache Manager...

ğŸ“ Cache path generation:
   Old format: recv_all_20251027_170308_vlm0.pt
   New format: episode_20251030_025119_vlm150.pt

ğŸ’¾ Save and load test:
   Saved: test_dataset_vlm0.pt
   Loaded: torch.Size([1, 1, 3072])
   Match: True

ğŸ“Š Cache statistics:
   cache_dir: /tmp/test_vla_cache
   total_files: 1
   total_size_gb: 0.000012
   limit_gb: 1.0
   usage_percent: 0.0012

ğŸ“‹ Cached datasets:
   test_dataset: 1 cached VLM features

âœ… All tests passed!
```

### Dataset ë¡œë”© í…ŒìŠ¤íŠ¸
```bash
# Old format dataset
python -c "
from vla_datasets.unified_dataset import UnifiedVLADataset
ds = UnifiedVLADataset(
    data_dir='/home/najo/NAS/VLA/dataset/dataset/recv_all_20251027_170308',
    format='old'
)
print(f'Total samples: {len(ds)}')
print(f'Cached VL features: {ds.cache_found_count}/{len(ds.vl_cache_files)}')
"

# New format dataset
python -c "
from vla_datasets.unified_dataset import UnifiedVLADataset
ds = UnifiedVLADataset(
    data_dir='/home/najo/NAS/VLA/dataset/New_dataset/Yellow_point/episode_20251030_025119',
    format='new'
)
print(f'Total samples: {len(ds)}')
print(f'Cached VL features: {ds.cache_found_count}/{len(ds.vl_cache_files)}')
"
```

### ì „ì²´ Training í…ŒìŠ¤íŠ¸
```bash
# Single GPU
python TRAIN_Unified.py --mode train --model-type regression

# Multi-GPU
torchrun --nproc_per_node=4 TRAIN_Unified.py --mode train --model-type regression
```

**ê¸°ëŒ€ ì¶œë ¥**:
```
ğŸ“¦ Loaded episode_20251030_025209 (new format)
   Samples: 169, Sensor: True, VL Cache: 57/57  âœ…
```

---

## ğŸ“Š ìºì‹œ ë””ë ‰í† ë¦¬ êµ¬ì¡°

```
/home/najo/NAS/VLA/dataset/cache/qwen_vl_features/
â”œâ”€â”€ recv_all_20251027_170308_vlm0.pt
â”œâ”€â”€ recv_all_20251027_170308_vlm3.pt
â”œâ”€â”€ recv_all_20251027_170308_vlm6.pt
â”œâ”€â”€ episode_20251030_025119_vlm0.pt
â”œâ”€â”€ episode_20251030_025119_vlm10.pt
â”œâ”€â”€ episode_20251030_025119_vlm20.pt
â””â”€â”€ ...
```

**íŠ¹ì§•**:
- íŒŒì¼ ì´ë¦„ë§Œ ë´ë„ ì–´ë–¤ ë°ì´í„°ì…‹ì˜ ì–´ë–¤ VLM ì¸ë±ìŠ¤ì¸ì§€ ëª…í™•
- Instructionì´ë‚˜ image pathê°€ ë°”ë€Œì–´ë„ íŒŒì¼ ì´ë¦„ ë™ì¼
- ë””ë²„ê¹… ë° ê´€ë¦¬ ìš©ì´

---

## ğŸ›ï¸ VLACacheManager ì„¤ì •

### ê¸°ë³¸ ì„¤ì •
```python
from vla_cache_manager import get_cache_manager

cache_mgr = get_cache_manager(
    cache_dir="/home/najo/NAS/VLA/dataset/cache/qwen_vl_features",
    cache_limit_gb=50.0  # 50GB ì œí•œ
)
```

### ìºì‹œ í†µê³„ í™•ì¸
```python
stats = cache_mgr.get_cache_stats()
print(stats)
# {
#     'cache_dir': '/home/najo/NAS/VLA/dataset/cache/qwen_vl_features',
#     'total_files': 1234,
#     'total_size_gb': 45.2,
#     'limit_gb': 50.0,
#     'usage_percent': 90.4
# }
```

### ìºì‹œëœ ë°ì´í„°ì…‹ ëª©ë¡
```python
datasets = cache_mgr.list_cached_datasets()
print(datasets)
# {
#     'recv_all_20251027_170308': [0, 3, 6, 9, ...],
#     'episode_20251030_025119': [0, 10, 20, 30, ...]
# }
```

### ìºì‹œ ì‚­ì œ (ì£¼ì˜!)
```python
cache_mgr.clear_cache(confirm=True)
```

---

## âš™ï¸ ì£¼ìš” ë™ì‘ ì›ë¦¬

### 1. Dataset ì´ˆê¸°í™” ì‹œ
```python
def __init__(self, data_dir, ...):
    ...
    self._scan_vl_cache()  # ìºì‹œ ë¯¸ë¦¬ ìŠ¤ìº”
```

`_scan_vl_cache()`ëŠ”:
1. VLACacheManager ì´ˆê¸°í™”
2. ëª¨ë“  ì˜ˆìƒ VLM ì¸ë±ìŠ¤ì— ëŒ€í•´ ìºì‹œ ì¡´ì¬ í™•ì¸
3. `self.vl_cache_files` ë”•ì…”ë„ˆë¦¬ êµ¬ì„±:
   - Key: vlm_idx
   - Value: Path ë˜ëŠ” None

### 2. `__getitem__()` í˜¸ì¶œ ì‹œ
```python
def _load_vl_or_images(self, vlm_idx):
    cache_path = self.vl_cache_files.get(vlm_idx)

    if cache_path:
        vl_cache = cache_mgr.load_cache(dataset_name, vlm_idx, device="cpu")
        if vl_cache is not None:
            return vl_cache, None  # ìºì‹œ ë°˜í™˜

    # ìºì‹œ ì—†ìœ¼ë©´ image paths ë°˜í™˜
    return None, image_paths
```

### 3. VLM ì‹¤í–‰ í›„ ì €ì¥ (Make_VL_cache.py)
```python
pooled_batch = vl_tokens_batch.mean(dim=1, keepdim=True)

for j, item in enumerate(sub_items):
    cache_mgr.save_cache(
        dataset_name=item["dataset_name"],
        vlm_idx=item["vlm_idx"],
        vl_features=pooled_batch[j:j+1]
    )
```

`save_cache()` ë‚´ë¶€:
1. Atomic save with file locking (race condition ë°©ì§€)
2. ì´ë¯¸ ì¡´ì¬í•˜ë©´ ìŠ¤í‚µ
3. ì €ì¥ í›„ ìë™ìœ¼ë¡œ `_enforce_cache_limit()` í˜¸ì¶œ
4. ìš©ëŸ‰ ì´ˆê³¼ ì‹œ ì˜¤ë˜ëœ íŒŒì¼ë¶€í„° ì‚­ì œ

---

## ğŸš€ ì„±ëŠ¥ ë° ì•ˆì •ì„±

### ì´ì „ ì‹œìŠ¤í…œ ë¬¸ì œì 
- âŒ Instruction ë³€ê²½ â†’ ìºì‹œ ë¯¸ìŠ¤
- âŒ Image path ë³€ê²½ â†’ ìºì‹œ ë¯¸ìŠ¤
- âŒ Hash collision ê°€ëŠ¥ì„±
- âŒ ë””ë²„ê¹… ì–´ë ¤ì›€ (íŒŒì¼ ì´ë¦„ì´ hash)

### ìƒˆë¡œìš´ ì‹œìŠ¤í…œ ì¥ì 
- âœ… ì™„ì „íˆ ê²°ì •ë¡ ì  (dataset name + vlm_idxë§Œ ì‚¬ìš©)
- âœ… Instruction/Image path ë³€ê²½ì— ê°•ê±´
- âœ… íŒŒì¼ ì´ë¦„ë§Œ ë´ë„ ë‚´ìš© íŒŒì•… ê°€ëŠ¥
- âœ… Atomic saveë¡œ ë™ì‹œ ì ‘ê·¼ ì•ˆì „
- âœ… ìë™ ìºì‹œ ìš©ëŸ‰ ê´€ë¦¬
- âœ… í†µê³„ ë° ê´€ë¦¬ ê¸°ëŠ¥ ì œê³µ

### ì˜ˆìƒ ìºì‹œ ì ì¤‘ë¥ 
- **ê¸°ì¡´ ì‹œìŠ¤í…œ**: 0% (ê²½ë¡œ ë³€ê²½ ì‹œ)
- **ìƒˆë¡œìš´ ì‹œìŠ¤í…œ**: ~100% (ë°ì´í„°ì…‹ì´ ë™ì¼í•˜ë©´)

---

## ğŸ”§ Troubleshooting

### ë¬¸ì œ: ìºì‹œë¥¼ ëª» ì°¾ìŒ (VL Cache: 0/N)

**ì²´í¬ë¦¬ìŠ¤íŠ¸**:
1. ìºì‹œ ë””ë ‰í† ë¦¬ í™•ì¸:
```bash
ls /home/najo/NAS/VLA/dataset/cache/qwen_vl_features/
```

2. Dataset ì´ë¦„ í™•ì¸:
```python
from pathlib import Path
data_dir = Path("/home/najo/NAS/VLA/dataset/New_dataset/Yellow_point/episode_20251030_025119")
print(data_dir.name)  # episode_20251030_025119
```

3. ì˜ˆìƒ ìºì‹œ íŒŒì¼ ì´ë¦„:
```
episode_20251030_025119_vlm0.pt
episode_20251030_025119_vlm10.pt
episode_20251030_025119_vlm20.pt
...
```

4. ì‹¤ì œ ìºì‹œ íŒŒì¼ê³¼ ë¹„êµ

### ë¬¸ì œ: ìºì‹œ ìƒì„±ì´ ë„ˆë¬´ ëŠë¦¼

**í•´ê²°ì±…**:
1. `batch_size` ì¦ê°€ (GPU ë©”ëª¨ë¦¬ê°€ ì¶©ë¶„í•˜ë©´)
2. `num_workers` ì¡°ì •
3. `micro_bs` ì¦ê°€ (OOMì´ ì•ˆ ë‚˜ë©´)

### ë¬¸ì œ: ìºì‹œ ìš©ëŸ‰ ì´ˆê³¼

**í•´ê²°ì±…**:
1. `cache_limit_gb` ì¦ê°€:
```python
cache_mgr = get_cache_manager(cache_limit_gb=100.0)
```

2. ë˜ëŠ” ì˜¤ë˜ëœ ìºì‹œ ìˆ˜ë™ ì‚­ì œ:
```python
cache_mgr.clear_cache(confirm=True)
```

---

## ğŸ“ ë§ˆì´ê·¸ë ˆì´ì…˜ ê°€ì´ë“œ

### ê¸°ì¡´ Hash ê¸°ë°˜ ìºì‹œê°€ ìˆëŠ” ê²½ìš°

**Option 1**: ìºì‹œ ì¬ìƒì„± (ê¶Œì¥)
```bash
# ê¸°ì¡´ ìºì‹œ ë°±ì—…
mv /home/najo/NAS/VLA/dataset/cache/qwen_vl_features \
   /home/najo/NAS/VLA/dataset/cache/qwen_vl_features_old

# ìƒˆë¡œìš´ ìºì‹œ ìƒì„±
python Make_VL_cache.py
```

**Option 2**: ìºì‹œ ë³€í™˜ ìŠ¤í¬ë¦½íŠ¸ (í•„ìš”ì‹œ ì‘ì„± ê°€ëŠ¥)

---

**ìˆ˜ì • ì™„ë£Œ ë‚ ì§œ**: 2025-11-03
**ì‘ì„±ì**: Claude Code
