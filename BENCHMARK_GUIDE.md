# Real-time Inference Benchmark Guide

ì‹¤ì‹œê°„ ì¶”ë¡  ì„±ëŠ¥ì„ ì¸¡ì •í•˜ê³  ë¶„ì„í•˜ê¸° ìœ„í•œ ë²¤ì¹˜ë§ˆí¬ ë„êµ¬ì…ë‹ˆë‹¤.

## ğŸ“‹ ëª©ì°¨

1. [ê°œìš”](#ê°œìš”)
2. [ì¸¡ì • í•­ëª©](#ì¸¡ì •-í•­ëª©)
3. [ì‚¬ìš© ë°©ë²•](#ì‚¬ìš©-ë°©ë²•)
4. [ë²¤ì¹˜ë§ˆí¬ ì‹œë‚˜ë¦¬ì˜¤](#ë²¤ì¹˜ë§ˆí¬-ì‹œë‚˜ë¦¬ì˜¤)
5. [ê²°ê³¼ í•´ì„](#ê²°ê³¼-í•´ì„)

---

## ê°œìš”

### ëª©ì 
- VL ëª¨ë¸, Sensor Encoder, Action Expertì˜ **ê°œë³„ ì¶”ë¡  ì‹œê°„** ì¸¡ì •
- Regression vs Flow Matching ëª¨ë¸ ë¹„êµ
- ì¹´ë©”ë¼ view ê°œìˆ˜ì— ë”°ë¥¸ ì„±ëŠ¥ ë³€í™” ë¶„ì„
- Sensor/Robot States ì…ë ¥ ìœ ë¬´ì— ë”°ë¥¸ ì„±ëŠ¥ ì˜í–¥ ë¶„ì„

### íŠ¹ì§•
- âœ… **VL ìºì‹œ ì™„ì „ ë¹„í™œì„±í™”** (ì‹¤ì œ ì‹¤ì‹œê°„ ì¶”ë¡  í™˜ê²½ ì‹œë®¬ë ˆì´ì…˜)
- âœ… **ì»´í¬ë„ŒíŠ¸ë³„ ì‹œê°„ ì¸¡ì •** (VL, Sensor, Action ë¶„ë¦¬)
- âœ… **GPU Synchronization** (ì •í™•í•œ ì‹œê°„ ì¸¡ì •)
- âœ… **Warmup + ë°˜ë³µ ì¸¡ì •** (ì•ˆì •ì ì¸ ê²°ê³¼)
- âœ… **ë¹„ë™ê¸° ëª¨ë¸ ì§€ì›** (VLM reuse pattern)
- âœ… **ì‹œê°í™” ìë™ ìƒì„±** (ê·¸ë˜í”„ ë° í‘œ)

### âš ï¸ ì¤‘ìš”: VL ìºì‹œ ë¹„í™œì„±í™”
ì‹¤ì‹œê°„ ì¶”ë¡ ì—ì„œëŠ” ë§¤ í”„ë ˆì„ ìƒˆë¡œìš´ ì´ë¯¸ì§€ê°€ ì…ë ¥ë˜ë¯€ë¡œ **VL ìºì‹œë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤**.
ë”°ë¼ì„œ ë²¤ì¹˜ë§ˆí¬ì—ì„œë„ `cache_enabled=False`ë¡œ ì„¤ì •í•˜ì—¬ ì‹¤ì œ í™˜ê²½ì„ ì •í™•íˆ ì‹œë®¬ë ˆì´ì…˜í•©ë‹ˆë‹¤.

```python
# ë²¤ì¹˜ë§ˆí¬ ì´ˆê¸°í™” ì‹œ ìë™ìœ¼ë¡œ ì„¤ì •ë¨
self.model.cache_enabled = False  # âœ… ì‹¤ì‹œê°„ ì¶”ë¡  í™˜ê²½
```

í•™ìŠµ ì‹œì—ëŠ” VLM reuse (ì˜ˆ: 3íšŒ)ë¥¼ ì‚¬ìš©í•˜ì—¬ VL encodingì„ ì ˆì•½í•˜ì§€ë§Œ,
**ë²¤ì¹˜ë§ˆí¬ëŠ” ë§¤ë²ˆ ìƒˆë¡œìš´ VL encodingì„ ìˆ˜í–‰**í•˜ì—¬ worst-case ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ì¸¡ì •í•©ë‹ˆë‹¤.

---

## ì¸¡ì • í•­ëª©

### 1. VL Encoding Time
**ì¸¡ì • ë‚´ìš©:**
- Text + Image â†’ Vision-Language features ìƒì„± ì‹œê°„
- **ìºì‹œ ì—†ì´ ë§¤ë²ˆ ìƒˆë¡œ encoding** (ì‹¤ì‹œê°„ í™˜ê²½)

**í¬í•¨ ì‘ì—…:**
1. Image loading & preprocessing
2. Tokenization
3. Qwen2.5-VL forward pass (3B parameters)
4. Feature extraction (hidden states)
5. **Mean pooling** (sequence â†’ single vector)

**VL Processing Pipeline:**
```python
# Step 1-3: VL model forward
vl_outputs = vl_model(**inputs, output_hidden_states=True, use_cache=False)
vl_tokens = vl_outputs.hidden_states[-1]  # (B, seq_len, 3072)

# Step 4-5: Pool to match training format
vl_features = vl_tokens.mean(dim=1, keepdim=True)  # (B, 1, 3072)
```

**ì˜ˆìƒ ì‹œê°„:**
- 1 view: ~150-250ms
- 3 views: ~250-350ms
- 5 views: ~350-500ms

**ì£¼ì˜:**
- VL encodingì€ **ê°€ì¥ í° ë³‘ëª©** (ì „ì²´ì˜ 90% ì´ìƒ)
- ì‹¤ì‹œê°„ ì¶”ë¡ ì—ì„œëŠ” ë¹„ë™ê¸° ì²˜ë¦¬ í•„ìˆ˜
- VLM reuseë¡œ overhead ë¶„ì‚° ê°€ëŠ¥
- **Pooling ë°©ì‹ì´ í•™ìŠµ ì‹œ ìºì‹œì™€ ë™ì¼í•´ì•¼ í•¨**

---

### 2. Sensor Encoding Time
**ì¸¡ì • ë‚´ìš©:**
- Sensor data + Robot states â†’ Sensor features ìƒì„± ì‹œê°„

**í¬í•¨ ì‘ì—…:**
- Sensor data preprocessing
- Robot states encoding
- Temporal 1D CNN encoding
- Feature pooling

**ì˜ˆìƒ ì‹œê°„:** ~5-15ms

---

### 3. Action Prediction Time
**ì¸¡ì • ë‚´ìš©:**
- VL features + Sensor features â†’ Action sequence ìƒì„± ì‹œê°„

**í¬í•¨ ì‘ì—…:**
- Feature fusion (concat/cross-attention)
- Action expert forward pass
- **Regression**: Direct prediction
- **Flow Matching**: ODE sampling

**ì˜ˆìƒ ì‹œê°„:**
- Regression: ~10-20ms
- Flow Matching: ~30-50ms

---

### 4. End-to-End Time
**ì¸¡ì • ë‚´ìš©:**
- ì „ì²´ ì¶”ë¡  ì‹œê°„ (VL + Sensor + Action)

**ì˜ˆìƒ ì‹œê°„:** ~250-500ms (4-2 FPS)

---

## ì‚¬ìš© ë°©ë²•

### 1. ê¸°ë³¸ ì‚¬ìš©ë²•

#### A. Regression vs Flow Matching ë¹„êµ
```bash
python benchmark_realtime_inference.py \
    --checkpoint-regression ./checkpoints/regression_best.pt \
    --checkpoint-flow ./checkpoints/flow_matching_best.pt \
    --dataset-dir /path/to/episode_dir \
    --num-iterations 10
```

#### B. Regressionë§Œ í…ŒìŠ¤íŠ¸
```bash
python benchmark_realtime_inference.py \
    --checkpoint-regression ./checkpoints/regression_best.pt \
    --dataset-dir /path/to/episode_dir
```

#### C. Flow Matchingë§Œ í…ŒìŠ¤íŠ¸
```bash
python benchmark_realtime_inference.py \
    --checkpoint-flow ./checkpoints/flow_matching_best.pt \
    --dataset-dir /path/to/episode_dir
```

---

### 2. ê³ ê¸‰ ì˜µì…˜

#### A. ë°˜ë³µ íšŸìˆ˜ ì¡°ì •
```bash
python benchmark_realtime_inference.py \
    --checkpoint-regression ./checkpoints/regression_best.pt \
    --num-iterations 20  # ë” ì •í™•í•œ ì¸¡ì •
```

#### B. ì¹´ë©”ë¼ view ê°œìˆ˜ ì¡°ì •
```bash
# 3ê°œ viewë§Œ ì‚¬ìš© (ì†ë„ í–¥ìƒ)
python benchmark_realtime_inference.py \
    --checkpoint-regression ./checkpoints/regression_best.pt \
    --num-views 3
```

#### C. Sensor ë¹„í™œì„±í™”
```bash
python benchmark_realtime_inference.py \
    --checkpoint-regression ./checkpoints/regression_best.pt \
    --disable-sensor
```

#### D. Robot States ë¹„í™œì„±í™”
```bash
python benchmark_realtime_inference.py \
    --checkpoint-regression ./checkpoints/regression_best.pt \
    --disable-robot-states
```

#### E. GPU ì„ íƒ
```bash
python benchmark_realtime_inference.py \
    --checkpoint-regression ./checkpoints/regression_best.pt \
    --device cuda:1  # GPU 1 ì‚¬ìš©
```

---

### 3. ë¹„êµ ëª¨ë“œ

#### A. View ê°œìˆ˜ ë¹„êµ (1-5 views)
```bash
python benchmark_realtime_inference.py \
    --checkpoint-regression ./checkpoints/regression_best.pt \
    --compare-views
```

**ê²°ê³¼:**
- ê° view ê°œìˆ˜ë³„ ì„±ëŠ¥ ì¸¡ì •
- View ê°œìˆ˜ì— ë”°ë¥¸ latency/throughput ê·¸ë˜í”„ ìƒì„±

#### B. Sensor ìœ ë¬´ ë¹„êµ
```bash
python benchmark_realtime_inference.py \
    --checkpoint-regression ./checkpoints/regression_best.pt \
    --compare-sensors
```

**ê²°ê³¼:**
- Sensor ì‚¬ìš©/ë¯¸ì‚¬ìš© ì„±ëŠ¥ ë¹„êµ
- Sensor overhead ì¸¡ì •

---

### 4. ì¼ê´„ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸

**ëª¨ë“  ë²¤ì¹˜ë§ˆí¬ë¥¼ í•œë²ˆì— ì‹¤í–‰:**
```bash
bash run_benchmark.sh
```

**í¬í•¨ í…ŒìŠ¤íŠ¸:**
1. Regression vs Flow Matching
2. View ê°œìˆ˜ ë¹„êµ (1-5)
3. Sensor ìœ ë¬´ ë¹„êµ
4. ì§ì ‘ Sensor ë¹„êµ

---

## ë²¤ì¹˜ë§ˆí¬ ì‹œë‚˜ë¦¬ì˜¤

### ì‹œë‚˜ë¦¬ì˜¤ 1: ëª¨ë¸ ë¹„êµ
**ëª©ì :** Regression vs Flow Matching ì„±ëŠ¥ ë¹„êµ

**ëª…ë ¹ì–´:**
```bash
python benchmark_realtime_inference.py \
    --checkpoint-regression ./checkpoints/regression_best.pt \
    --checkpoint-flow ./checkpoints/flow_matching_best.pt \
    --num-iterations 20 \
    --output-dir ./benchmark_results/model_comparison
```

**ì˜ˆìƒ ê²°ê³¼:**
- Regressionì´ Flow Matchingë³´ë‹¤ **2-3ë°° ë¹ ë¦„**
- Flow Matchingì€ ODE samplingìœ¼ë¡œ ì¸í•œ overhead

---

### ì‹œë‚˜ë¦¬ì˜¤ 2: ì‹¤ì‹œê°„ ìš”êµ¬ì‚¬í•­ í™•ì¸
**ëª©ì :** 10Hz ì œì–´ ì£¼ê¸° ë‹¬ì„± ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸

**ìš”êµ¬ì‚¬í•­:**
- ì œì–´ ì£¼ê¸°: 100ms (10Hz)
- VLM reuse: 3íšŒ (300msë§ˆë‹¤ VL encoding)

**ëª…ë ¹ì–´:**
```bash
python benchmark_realtime_inference.py \
    --checkpoint-regression ./checkpoints/regression_best.pt \
    --num-views 3 \
    --num-iterations 20
```

**íŒë‹¨ ê¸°ì¤€:**
- Action Prediction < 50ms: âœ… ê°€ëŠ¥
- Action Prediction > 100ms: âŒ ë¶ˆê°€ëŠ¥
- VL Encodingì€ ë¹„ë™ê¸° ì²˜ë¦¬ (ë³„ë„ ìŠ¤ë ˆë“œ)

---

### ì‹œë‚˜ë¦¬ì˜¤ 3: ìµœì  View ê°œìˆ˜ ì°¾ê¸°
**ëª©ì :** ì„±ëŠ¥ê³¼ ì •í™•ë„ trade-off ë¶„ì„

**ëª…ë ¹ì–´:**
```bash
python benchmark_realtime_inference.py \
    --checkpoint-regression ./checkpoints/regression_best.pt \
    --compare-views \
    --num-iterations 20 \
    --output-dir ./benchmark_results/view_optimization
```

**ë¶„ì„:**
1. 1 view: ê°€ì¥ ë¹ ë¦„ (í•˜ì§€ë§Œ spatial info ë¶€ì¡±)
2. 3 views: ê· í˜•ì  (ì„±ëŠ¥ + ì •í™•ë„)
3. 5 views: ê°€ì¥ ëŠë¦¼ (í•˜ì§€ë§Œ ìµœê³  ì •í™•ë„)

---

### ì‹œë‚˜ë¦¬ì˜¤ 4: Sensor Impact ë¶„ì„
**ëª©ì :** Sensorê°€ ì„±ëŠ¥ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ ì¸¡ì •

**ëª…ë ¹ì–´:**
```bash
python benchmark_realtime_inference.py \
    --checkpoint-regression ./checkpoints/regression_best.pt \
    --compare-sensors \
    --num-iterations 20 \
    --output-dir ./benchmark_results/sensor_impact
```

**ë¶„ì„:**
- Sensor overhead: ~5-15ms
- Sensorê°€ ì •í™•ë„ í–¥ìƒì— ê¸°ì—¬í•˜ëŠ”ì§€ í™•ì¸ í•„ìš”

---

## ê²°ê³¼ í•´ì„

### ì¶œë ¥ í˜•ì‹

**í„°ë¯¸ë„ ì¶œë ¥ ì˜ˆì‹œ:**
```
============================================================
Results: Regression (regression)
============================================================

ğŸ“Š Timing Breakdown:
  VL Encoding:       287.34 Â± 12.45 ms
  Sensor Encoding:   8.72 Â± 1.23 ms
  Action Prediction: 15.67 Â± 2.11 ms
  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  Total (E2E):       311.73 Â± 13.89 ms
  Throughput:        3.21 FPS

ğŸ“ˆ Component Breakdown:
  VL Encoding:       92.2%
  Sensor Encoding:   2.8%
  Action Prediction: 5.0%
```

**í•´ì„:**
- VL Encodingì´ **ì „ì²´ ì‹œê°„ì˜ 92%** ì°¨ì§€ â†’ ë³‘ëª© ì§€ì 
- Action Predictionì€ ë§¤ìš° ë¹ ë¦„ (15ms)
- ë¹„ë™ê¸° ì²˜ë¦¬ë¡œ VL Encodingì„ ìˆ¨ê¸¸ ìˆ˜ ìˆìŒ

---

### ì €ì¥ íŒŒì¼

**1. JSON ê²°ê³¼ íŒŒì¼**
- `regression_results.json`: Regression ìƒì„¸ ê²°ê³¼
- `flow_matching_results.json`: Flow Matching ìƒì„¸ ê²°ê³¼

**ë‚´ìš©:**
```json
{
  "model_name": "Regression",
  "model_type": "regression",
  "vl_encoding": {
    "mean": 0.28734,
    "std": 0.01245,
    "min": 0.27123,
    "max": 0.31456
  },
  "total": {
    "mean": 0.31173,
    "fps": 3.21
  },
  "raw_results": [...]
}
```

**2. CSV ë¹„êµ í‘œ**
- `comparison.csv`: ëª¨ë¸ ê°„ ë¹„êµ í‘œ

**ë‚´ìš©:**
```csv
Model,Type,VL (ms),Sensor (ms),Action (ms),Total (ms),FPS
Regression,regression,287.34,8.72,15.67,311.73,3.21
Flow Matching,flow_matching,289.12,8.94,42.35,340.41,2.94
```

**3. ì‹œê°í™” ê·¸ë˜í”„**
- `comparison.png`: ì„±ëŠ¥ ë¹„êµ ê·¸ë˜í”„
  - ì™¼ìª½: ì»´í¬ë„ŒíŠ¸ë³„ ì‹œê°„ ë¶„í•´ (bar chart)
  - ì˜¤ë¥¸ìª½: ì „ì²´ ì‹œê°„ + FPS (bar + line plot)

---

### ë³‘ëª© ì§€ì  ë¶„ì„

**Case 1: VL Encodingì´ 90% ì´ìƒ**
```
VL Encoding:   92.2%
Sensor:        2.8%
Action:        5.0%
```

**í•´ê²°ì±…:**
- âœ… VLM reuse count ì¦ê°€ (3 â†’ 5)
- âœ… ë¹„ë™ê¸° VL encoding (ë³„ë„ ìŠ¤ë ˆë“œ)
- âœ… View ê°œìˆ˜ ê°ì†Œ (5 â†’ 3)
- âœ… ì´ë¯¸ì§€ í•´ìƒë„ ê°ì†Œ

---

**Case 2: Action Predictionì´ 30% ì´ìƒ**
```
VL Encoding:   60.0%
Sensor:        10.0%
Action:        30.0%  â† ë³‘ëª©
```

**í•´ê²°ì±…:**
- âœ… Flow Matching â†’ Regression ì „í™˜
- âœ… Action expert hidden dim ê°ì†Œ
- âœ… torch.compile ì ìš©

---

**Case 3: Sensor Encodingì´ 20% ì´ìƒ**
```
VL Encoding:   70.0%
Sensor:        20.0%  â† ë³‘ëª©
Action:        10.0%
```

**í•´ê²°ì±…:**
- âœ… Sensor window size ê°ì†Œ (650 â†’ 65)
- âœ… 1D CNN depth ê°ì†Œ
- âœ… Sensorë¥¼ ë¹„í™œì„±í™”í•˜ê³  ì„±ëŠ¥ í™•ì¸

---

### ì‹¤ì‹œê°„ ìš”êµ¬ì‚¬í•­ ì²´í¬ë¦¬ìŠ¤íŠ¸

#### 10Hz ì œì–´ ì£¼ê¸° (100ms)
- [ ] Action Prediction < 50ms
- [ ] VL Encoding ë¹„ë™ê¸° ì²˜ë¦¬
- [ ] Sensor Encoding < 10ms
- [ ] Total overhead < 70ms

#### 30Hz ì œì–´ ì£¼ê¸° (33ms)
- [ ] Action Prediction < 15ms
- [ ] Sensor Encoding < 5ms
- [ ] VL Encoding ë°±ê·¸ë¼ìš´ë“œ ì²˜ë¦¬
- [ ] Total overhead < 25ms

---

## ìµœì í™” ê¶Œì¥ ì‚¬í•­

### 1. VL Encoding ìµœì í™”
```python
# ì´ë¯¸ì§€ í•´ìƒë„ ê°ì†Œ
--image_resize_height 270  # 360 â†’ 270
--image_resize_width 480   # 640 â†’ 480

# View ê°œìˆ˜ ê°ì†Œ
--num-views 3  # 5 â†’ 3

# VLM reuse ì¦ê°€ (accuracy vs latency trade-off)
--vlm-reuse-count 5  # 3 â†’ 5
```

### 2. Model Optimization
```python
# torch.compile ì ìš© (10-20% speedup)
model = torch.compile(model, mode='max-autotune')

# FlashAttention-2 í™•ì¸
# ì´ë¯¸ ì‚¬ìš© ì¤‘: attn_implementation="flash_attention_2"
```

### 3. Sensor Optimization
```python
# Sensor window í¬ê¸° ê°ì†Œ
--sensor-window-size 32  # 65 â†’ 32

# Sensor ë¹„í™œì„±í™” (ì •í™•ë„ í™•ì¸ í•„ìš”)
--disable-sensor
```

---

## FAQ

**Q1: FPSê°€ ë„ˆë¬´ ë‚®ìŠµë‹ˆë‹¤ (< 2 FPS). ì–´ë–»ê²Œ í•´ì•¼ í•˜ë‚˜ìš”?**

A: VL Encodingì´ ë³‘ëª©ì¼ ê°€ëŠ¥ì„±ì´ ë†’ìŠµë‹ˆë‹¤.
1. View ê°œìˆ˜ ê°ì†Œ (5 â†’ 3)
2. ì´ë¯¸ì§€ í•´ìƒë„ ê°ì†Œ
3. VLM reuse count ì¦ê°€
4. ë¹„ë™ê¸° VL encoding êµ¬í˜„

---

**Q2: Flow Matchingì´ Regressionë³´ë‹¤ ì–¼ë§ˆë‚˜ ëŠë¦°ê°€ìš”?**

A: Action Prediction ì‹œê°„ ê¸°ì¤€:
- Regression: ~10-20ms
- Flow Matching: ~30-50ms (2-3ë°° ì°¨ì´)

í•˜ì§€ë§Œ VL Encodingì„ ë¹„ë™ê¸°ë¡œ ì²˜ë¦¬í•˜ë©´ ì „ì²´ E2E ì°¨ì´ëŠ” ì‘ìŒ.

---

**Q3: ì‹¤ì‹œê°„ 10Hz ì œì–´ê°€ ê°€ëŠ¥í•œê°€ìš”?**

A: VL Encodingì„ ë¹„ë™ê¸°ë¡œ ì²˜ë¦¬í•˜ë©´ ê°€ëŠ¥í•©ë‹ˆë‹¤.
- VL Encoding: ë³„ë„ ìŠ¤ë ˆë“œì—ì„œ 300msë§ˆë‹¤ ì‹¤í–‰ (reuse=3)
- Action Prediction: ë©”ì¸ ë£¨í”„ì—ì„œ 100msë§ˆë‹¤ ì‹¤í–‰

---

**Q4: Sensorê°€ ì„±ëŠ¥ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì€?**

A: OverheadëŠ” ì‘ì§€ë§Œ (5-15ms), ì •í™•ë„ í–¥ìƒ íš¨ê³¼ë¥¼ í™•ì¸í•´ì•¼ í•©ë‹ˆë‹¤.
`--compare-sensors` ì˜µì…˜ìœ¼ë¡œ ë¹„êµí•˜ì„¸ìš”.

---

**Q5: ì—¬ëŸ¬ GPUì—ì„œ ë™ì‹œì— í…ŒìŠ¤íŠ¸í•˜ë ¤ë©´?**

A:
```bash
# GPU 0
python benchmark_realtime_inference.py --device cuda:0 &

# GPU 1
python benchmark_realtime_inference.py --device cuda:1 &

wait
```

---

## ë‹¤ìŒ ë‹¨ê³„

1. **ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰**
   ```bash
   bash run_benchmark.sh
   ```

2. **ê²°ê³¼ ë¶„ì„**
   - `benchmark_results/` í´ë” í™•ì¸
   - ê·¸ë˜í”„ ë° CSV íŒŒì¼ ê²€í† 

3. **ìµœì í™” ì ìš©**
   - ë³‘ëª© ì§€ì  íŒŒì•…
   - ìµœì í™” ê¶Œì¥ ì‚¬í•­ ì ìš©

4. **ì‹¤ì œ í™˜ê²½ í…ŒìŠ¤íŠ¸**
   - Real robotì—ì„œ ì‹¤ì‹œê°„ ì¶”ë¡  í…ŒìŠ¤íŠ¸
   - Latency ëª¨ë‹ˆí„°ë§

---

**ì‘ì„±ì¼:** 2025-01-04
**ë²„ì „:** v1.0
